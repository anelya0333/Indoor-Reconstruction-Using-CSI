#!/usr/bin/env python3
"""
train_csi2image.py
===============================================================================
Purpose
===============================================================================
Train a simple baseline neural network that reconstructs RGB image frames
from normalized CSI (Channel State Information) feature vectors.

This script represents the final stage of the CSI-video pipeline:
1. Uses the aligned and normalized CSI feature data (`features_norm.npy`)
   generated by previous preprocessing scripts.
2. Loads paired frame image paths from split lists (`train.txt`, `val.txt`).
3. Defines a PyTorch dataset and model that maps CSI → image.
4. Trains using L1 reconstruction loss, logs basic metrics, and saves
   checkpointed models and visual samples.

===============================================================================
Model Architecture
===============================================================================
**CSI2Image** (fully connected → convolutional decoder):

    Input:  D-dimensional CSI feature vector
    ↓
    MLP:    Linear layers → latent tensor (C0×16×16)
    ↓
    Decoder: series of ConvTranspose2d upsampling blocks
    ↓
    Output: 3×256×256 RGB image (values in [0, 1])

===============================================================================
Usage
===============================================================================
    python train_csi2image.py \
        --frames_root dataset_out/frames \
        --splits_dir dataset_out/splits \
        --batch 16 \
        --lr 2e-4 \
        --epochs 50 \
        --out runs/baseline \
        --base_ch 64

===============================================================================
Inputs
===============================================================================
- frames_root : Directory containing resized image frames.
- splits_dir  : Directory with train/val/test splits and normalized features.
  Expected files:
      - features_norm.npy
      - train.txt / val.txt / test.txt
      - idx_train.npy / idx_val.npy / idx_test.npy

===============================================================================
Outputs
===============================================================================
Written to `--out` directory:
| File | Description |
|-------|-------------|
| last.pt | Latest checkpoint |
| best.pt | Best checkpoint (lowest validation loss) |
| samples_epoch_XXX.jpg | Grid comparing ground truth vs predictions |
| Console JSON logs | Training and validation metrics |

===============================================================================
Requirements
===============================================================================
- Python ≥3.8
- PyTorch ≥2.0
- torchvision
- Pillow
- NumPy
===============================================================================
"""

import os
import json
import math
import argparse
import random
from pathlib import Path

import numpy as np
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
import torchvision.utils as vutils


# =============================================================================
# Dataset Definition
# =============================================================================

class CSIDataset(Dataset):
    """
    PyTorch Dataset for loading paired (CSI feature, image) samples.

    Each row corresponds to one frame entry in `train.txt` / `val.txt`
    and its aligned CSI feature vector.

    Attributes:
        frames_root (Path): Root directory containing frame images.
        imgs (list[str]): Relative image paths.
        X (np.ndarray): Normalized CSI feature matrix (N×D).
        idx (np.ndarray): Row indices mapping images to feature rows.
        to_tensor (torchvision.transforms.Compose): Transform pipeline.

    Args:
        frames_root (str | Path): Directory containing images.
        list_txt (str): Path to text file listing frame image paths.
        features_norm_npy (str): Path to normalized CSI feature array (.npy).
        idx_npy (str, optional): Path to array of feature row indices.
        size (int, optional): Target resize dimension (default=256).
    """
    def __init__(self, frames_root, list_txt, features_norm_npy, idx_npy=None, size=256):
        self.frames_root = Path(frames_root)
        with open(list_txt) as f:
            self.imgs = [line.strip() for line in f if line.strip()]

        self.X = np.load(features_norm_npy)  # (N, D)
        if idx_npy is not None:
            # Use explicit index mapping from split
            self.idx = np.load(idx_npy)
        else:
            # Default: assume lines correspond 1-to-1 with features.npy order
            self.idx = np.arange(len(self.imgs))

        assert self.X.shape[0] >= self.idx.max() + 1, "features and indices mismatch"

        # Standard image preprocessing (resize + normalization to [0,1])
        self.to_tensor = T.Compose([
            T.Resize((size, size), interpolation=T.InterpolationMode.BILINEAR),
            T.ToTensor(),
        ])

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, i):
        """
        Returns:
            tuple(torch.Tensor, torch.Tensor):
                - x: CSI feature vector, shape (D,)
                - y: Image tensor, shape (3, H, W) in [0, 1]
        """
        img_path = self.frames_root / self.imgs[i]
        img = Image.open(img_path).convert("RGB")
        y = self.to_tensor(img)
        x = self.X[self.idx[i]].astype(np.float32)
        return torch.from_numpy(x), y


# =============================================================================
# Model Definition
# =============================================================================

class CSI2Image(nn.Module):
    """
    Baseline CSI→Image generator network.

    Architecture:
        [CSI vector → MLP → 16×16 feature map → 4× upsampling blocks → RGB image]

    Args:
        d_in (int): Input feature dimension (number of CSI amplitudes).
        base_ch (int): Base channel multiplier controlling model capacity.
    """
    def __init__(self, d_in, base_ch=64):
        super().__init__()
        c0 = base_ch * 4  # Starting channels at 16×16 resolution

        # MLP projection from 1D CSI vector → 2D latent map
        self.mlp = nn.Sequential(
            nn.Linear(d_in, 1024), nn.ReLU(inplace=True),
            nn.Linear(1024, 2048), nn.ReLU(inplace=True),
            nn.Linear(2048, c0 * 16 * 16),
        )

        # Transposed convolutions progressively upsample to 256×256
        self.up = nn.Sequential(
            nn.BatchNorm2d(c0),
            nn.ConvTranspose2d(c0, base_ch * 4, 4, 2, 1), nn.ReLU(True),   # 32×32
            nn.ConvTranspose2d(base_ch * 4, base_ch * 2, 4, 2, 1), nn.ReLU(True), # 64×64
            nn.ConvTranspose2d(base_ch * 2, base_ch, 4, 2, 1), nn.ReLU(True),     # 128×128
            nn.ConvTranspose2d(base_ch, 64, 4, 2, 1), nn.ReLU(True),              # 256×256
            nn.Conv2d(64, 3, 3, 1, 1), nn.Sigmoid()                               # RGB output
        )

    def forward(self, x):
        """
        Forward pass from CSI vector → reconstructed image.
        Args:
            x (torch.Tensor): Input CSI features (B×D)
        Returns:
            torch.Tensor: Reconstructed RGB image (B×3×256×256)
        """
        b = x.shape[0]
        h = self.mlp(x).view(b, -1, 16, 16)
        y = self.up(h)
        return y


# =============================================================================
# Evaluation Metrics
# =============================================================================

def psnr(x, y, eps=1e-8):
    """Compute Peak Signal-to-Noise Ratio (PSNR) in dB."""
    mse = torch.mean((x - y) ** 2)
    return -10 * torch.log10(mse + eps)

def ssim_tiny(x, y):
    """
    Lightweight SSIM approximation (no windowing) for quick validation.

    Returns a scalar similarity value between [0,1], higher is better.
    """
    mu_x, mu_y = x.mean(), y.mean()
    var_x, var_y = x.var(), y.var()
    cov_xy = ((x - mu_x) * (y - mu_y)).mean()
    c1, c2 = 0.01 ** 2, 0.03 ** 2
    return ((2 * mu_x * mu_y + c1) * (2 * cov_xy + c2)) / (
        (mu_x ** 2 + mu_y ** 2 + c1) * (var_x + var_y + c2)
    )


# =============================================================================
# Training Loop
# =============================================================================

def main():
    """Main entry point: initialize datasets, train model, log progress, save outputs."""
    # -------------------------------------------------------------------------
    # Argument parsing
    # -------------------------------------------------------------------------
    ap = argparse.ArgumentParser(description="Train CSI→Image reconstruction model.")
    ap.add_argument("--frames_root", default="dataset_out/frames", help="Directory with frame images.")
    ap.add_argument("--splits_dir", default="dataset_out/splits", help="Directory containing dataset splits.")
    ap.add_argument("--batch", type=int, default=16, help="Batch size.")
    ap.add_argument("--lr", type=float, default=2e-4, help="Learning rate.")
    ap.add_argument("--epochs", type=int, default=50, help="Number of training epochs.")
    ap.add_argument("--out", default="runs/baseline", help="Output directory for checkpoints/samples.")
    ap.add_argument("--base_ch", type=int, default=64, help="Base channel multiplier for decoder.")
    args = ap.parse_args()

    os.makedirs(args.out, exist_ok=True)

    # -------------------------------------------------------------------------
    # Data loading
    # -------------------------------------------------------------------------
    feats = os.path.join(args.splits_dir, "features_norm.npy")
    train_txt = os.path.join(args.splits_dir, "train.txt")
    val_txt   = os.path.join(args.splits_dir, "val.txt")
    idx_train = os.path.join(args.splits_dir, "idx_train.npy")
    idx_val   = os.path.join(args.splits_dir, "idx_val.npy")

    X = np.load(feats)
    d_in = X.shape[1]

    # Initialize datasets and data loaders
    ds_tr = CSIDataset(args.frames_root, train_txt, feats, idx_train)
    ds_va = CSIDataset(args.frames_root, val_txt, feats, idx_val)
    dl_tr = DataLoader(ds_tr, batch_size=args.batch, shuffle=True, num_workers=2, pin_memory=True)
    dl_va = DataLoader(ds_va, batch_size=args.batch, shuffle=False, num_workers=2, pin_memory=True)

    # -------------------------------------------------------------------------
    # Model, optimizer, and loss setup
    # -------------------------------------------------------------------------
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CSI2Image(d_in, base_ch=args.base_ch).to(device)
    opt = torch.optim.AdamW(model.parameters(), lr=args.lr)
    l1 = nn.L1Loss()

    best_val = float("inf")

    # -------------------------------------------------------------------------
    # Training and validation loop
    # -------------------------------------------------------------------------
    for epoch in range(1, args.epochs + 1):
        model.train()
        tr_loss = tr_psnr = tr_ssim = 0.0

        for xb, yb in dl_tr:
            xb, yb = xb.to(device), yb.to(device)
            yhat = model(xb)
            loss = l1(yhat, yb)

            opt.zero_grad()
            loss.backward()
            opt.step()

            tr_loss += loss.item() * xb.size(0)
            tr_psnr += psnr(yhat.detach(), yb).item() * xb.size(0)
            tr_ssim += ssim_tiny(yhat.detach(), yb).item() * xb.size(0)

        ntr = len(ds_tr)
        log = {
            "epoch": epoch,
            "train/l1": tr_loss / ntr,
            "train/psnr": tr_psnr / ntr,
            "train/ssim_approx": tr_ssim / ntr,
        }

        # ---------------------------------------------------------------------
        # Validation phase
        # ---------------------------------------------------------------------
        model.eval()
        va_loss = va_psnr = va_ssim = 0.0
        with torch.no_grad():
            for xb, yb in dl_va:
                xb, yb = xb.to(device), yb.to(device)
                yhat = model(xb)
                loss = l1(yhat, yb)
                va_loss += loss.item() * xb.size(0)
                va_psnr += psnr(yhat, yb).item() * xb.size(0)
                va_ssim += ssim_tiny(yhat, yb).item() * xb.size(0)

        nva = len(ds_va)
        log.update({
            "val/l1": va_loss / nva,
            "val/psnr": va_psnr / nva,
            "val/ssim_approx": va_ssim / nva,
        })

        # Print metrics as JSON for easy parsing/logging
        print(json.dumps(log))

        # ---------------------------------------------------------------------
        # Sample visualization
        # ---------------------------------------------------------------------
        if epoch % 5 == 0:
            xb, yb = next(iter(dl_va))
            xb, yb = xb.to(device), yb.to(device)
            yhat = model(xb).clamp(0, 1)
            grid = vutils.make_grid(torch.cat([yb[:8], yhat[:8]], dim=0), nrow=8)
            vutils.save_image(grid, os.path.join(args.out, f"samples_epoch_{epoch:03d}.jpg"))

        # ---------------------------------------------------------------------
        # Checkpointing
        # ---------------------------------------------------------------------
        ckpt = {"model": model.state_dict(), "epoch": epoch, "d_in": d_in, "base_ch": args.base_ch}
        torch.save(ckpt, os.path.join(args.out, "last.pt"))
        if va_loss / nva < best_val:
            best_val = va_loss / nva
            torch.save(ckpt, os.path.join(args.out, "best.pt"))


# =============================================================================
# Entry Point
# =============================================================================
if __name__ == "__main__":
    main()
